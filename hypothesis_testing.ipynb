{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c996c103",
   "metadata": {},
   "source": [
    "# Detailed Hypothesis Testing on Movie Dataset\n",
    "This notebook performs a series of hypothesis tests on a movie dataset to determine if various features are associated with movie success.\n",
    "\n",
    "**Tests Included:**\n",
    "1. Budget vs. Success (t-test)\n",
    "2. Genre vs. Success (Chi-squared)\n",
    "3. Vote Average vs. Success (t-test)\n",
    "4. Runtime vs. Success (t-test)\n",
    "5. Vote Count vs. Success (t-test)\n",
    "6. Certification vs. Success (Chi-squared)\n",
    "7. Country vs. Success (Chi-squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11039a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8154e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_csv('dataset/moviesDb.csv')\n",
    "    print(\"Dataset loaded successfully for detailed hypothesis testing!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: moviesDb.csv not found. Cannot perform detailed hypothesis testing.\")\n",
    "    df = None\n",
    "\n",
    "df.head() if df is not None else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acec7938",
   "metadata": {},
   "source": [
    "## Hypothesis Test: Budget vs. Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22168bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    group1 = df[df['success'] == True]['budget'].dropna()\n",
    "    group2 = df[df['success'] == False]['budget'].dropna()\n",
    "    display(group1.describe())\n",
    "    display(group2.describe())\n",
    "\n",
    "    if len(group1) > 1 and len(group2) > 1:\n",
    "        ttest = stats.ttest_ind(group1, group2, equal_var=False, alternative='greater')\n",
    "        print(f\"t-statistic = {ttest.statistic:.4f}, p-value = {ttest.pvalue:.4f}\")\n",
    "\n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        mean1, mean2 = group1.mean(), group2.mean()\n",
    "        std1, std2 = group1.std(), group2.std()\n",
    "        pooled_std = np.sqrt(((n1 - 1)*std1**2 + (n2 - 1)*std2**2)/(n1 + n2 - 2))\n",
    "        cohen_d = (mean1 - mean2) / pooled_std\n",
    "        print(f\"Cohen's d = {cohen_d:.4f}\")\n",
    "    else:\n",
    "        print(\"Insufficient data for t-test on budget.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af45b83",
   "metadata": {},
   "source": [
    "## Hypothesis Test: Vote Average vs. Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0d7bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    group1 = df[df['success'] == True]['vote_average'].dropna()\n",
    "    group2 = df[df['success'] == False]['vote_average'].dropna()\n",
    "    display(group1.describe())\n",
    "    display(group2.describe())\n",
    "\n",
    "    if len(group1) > 1 and len(group2) > 1:\n",
    "        ttest = stats.ttest_ind(group1, group2, equal_var=False, alternative='greater')\n",
    "        print(f\"t-statistic = {ttest.statistic:.4f}, p-value = {ttest.pvalue:.4f}\")\n",
    "\n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        mean1, mean2 = group1.mean(), group2.mean()\n",
    "        std1, std2 = group1.std(), group2.std()\n",
    "        pooled_std = np.sqrt(((n1 - 1)*std1**2 + (n2 - 1)*std2**2)/(n1 + n2 - 2))\n",
    "        cohen_d = (mean1 - mean2) / pooled_std\n",
    "        print(f\"Cohen's d = {cohen_d:.4f}\")\n",
    "    else:\n",
    "        print(\"Insufficient data for t-test on vote_average.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc581b",
   "metadata": {},
   "source": [
    "## Hypothesis Test: Runtime vs. Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e2eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    group1 = df[df['success'] == True]['runtime'].dropna()\n",
    "    group2 = df[df['success'] == False]['runtime'].dropna()\n",
    "    display(group1.describe())\n",
    "    display(group2.describe())\n",
    "\n",
    "    if len(group1) > 1 and len(group2) > 1:\n",
    "        ttest = stats.ttest_ind(group1, group2, equal_var=False, alternative='two-sided')\n",
    "        print(f\"t-statistic = {ttest.statistic:.4f}, p-value = {ttest.pvalue:.4f}\")\n",
    "\n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        mean1, mean2 = group1.mean(), group2.mean()\n",
    "        std1, std2 = group1.std(), group2.std()\n",
    "        pooled_std = np.sqrt(((n1 - 1)*std1**2 + (n2 - 1)*std2**2)/(n1 + n2 - 2))\n",
    "        cohen_d = (mean1 - mean2) / pooled_std\n",
    "        print(f\"Cohen's d = {cohen_d:.4f}\")\n",
    "    else:\n",
    "        print(\"Insufficient data for t-test on runtime.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98842a15",
   "metadata": {},
   "source": [
    "## Hypothesis Test: Vote Count vs. Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c7999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    group1 = df[df['success'] == True]['vote_count'].dropna()\n",
    "    group2 = df[df['success'] == False]['vote_count'].dropna()\n",
    "    display(group1.describe())\n",
    "    display(group2.describe())\n",
    "\n",
    "    if len(group1) > 1 and len(group2) > 1:\n",
    "        ttest = stats.ttest_ind(group1, group2, equal_var=False, alternative='greater')\n",
    "        print(f\"t-statistic = {ttest.statistic:.4f}, p-value = {ttest.pvalue:.4f}\")\n",
    "\n",
    "        n1, n2 = len(group1), len(group2)\n",
    "        mean1, mean2 = group1.mean(), group2.mean()\n",
    "        std1, std2 = group1.std(), group2.std()\n",
    "        pooled_std = np.sqrt(((n1 - 1)*std1**2 + (n2 - 1)*std2**2)/(n1 + n2 - 2))\n",
    "        cohen_d = (mean1 - mean2) / pooled_std\n",
    "        print(f\"Cohen's d = {cohen_d:.4f}\")\n",
    "    else:\n",
    "        print(\"Insufficient data for t-test on vote_count.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171297f",
   "metadata": {},
   "source": [
    "## Hypothesis Test: Genre vs. Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    top_values = df['genre'].value_counts().nlargest(15).index.tolist()\n",
    "    filtered_df = df[df['genre'].isin(top_values)].copy()\n",
    "\n",
    "    if not filtered_df.empty:\n",
    "        crosstab = pd.crosstab(filtered_df['genre'], filtered_df['success'])\n",
    "        if crosstab.shape[0] > 1 and crosstab.shape[1] > 1:\n",
    "            chi2, p, dof, expected = stats.chi2_contingency(crosstab)\n",
    "            display(crosstab)\n",
    "            display(pd.DataFrame(expected, index=crosstab.index, columns=crosstab.columns))\n",
    "            print(f\"Chi-squared: {chi2:.4f}, p-value: {p:.4f}, dof: {dof}\")\n",
    "\n",
    "            n = crosstab.sum().sum()\n",
    "            min_dim = min(crosstab.shape) - 1\n",
    "            cramers_v = np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else float('nan')\n",
    "            print(f\"Cramer's V: {cramers_v:.4f}\")\n",
    "\n",
    "            low_expected = (expected < 5).sum()\n",
    "            total_cells = expected.size\n",
    "            if low_expected > 0:\n",
    "                print(f\"Warning: {low_expected} out of {total_cells} cells have expected count < 5.\")\n",
    "        else:\n",
    "            print(\"Insufficient dimensions for Chi-squared test.\")\n",
    "    else:\n",
    "        print(\"Filtered data is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2503c3f",
   "metadata": {},
   "source": [
    "## Hypothesis Test: Certification vs. Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fb0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    top_values = df['certification_US'].dropna().unique().tolist()\n",
    "    filtered_df = df.copy()\n",
    "\n",
    "    if not filtered_df.empty:\n",
    "        crosstab = pd.crosstab(filtered_df['certification_US'], filtered_df['success'])\n",
    "        if crosstab.shape[0] > 1 and crosstab.shape[1] > 1:\n",
    "            chi2, p, dof, expected = stats.chi2_contingency(crosstab)\n",
    "            display(crosstab)\n",
    "            display(pd.DataFrame(expected, index=crosstab.index, columns=crosstab.columns))\n",
    "            print(f\"Chi-squared: {chi2:.4f}, p-value: {p:.4f}, dof: {dof}\")\n",
    "\n",
    "            n = crosstab.sum().sum()\n",
    "            min_dim = min(crosstab.shape) - 1\n",
    "            cramers_v = np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else float('nan')\n",
    "            print(f\"Cramer's V: {cramers_v:.4f}\")\n",
    "\n",
    "            low_expected = (expected < 5).sum()\n",
    "            total_cells = expected.size\n",
    "            if low_expected > 0:\n",
    "                print(f\"Warning: {low_expected} out of {total_cells} cells have expected count < 5.\")\n",
    "        else:\n",
    "            print(\"Insufficient dimensions for Chi-squared test.\")\n",
    "    else:\n",
    "        print(\"Filtered data is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be0060",
   "metadata": {},
   "source": [
    "## Hypothesis Test: Country vs. Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed149001",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    top_values = df['country'].value_counts().nlargest(10).index.tolist()\n",
    "    filtered_df = df[df['country'].isin(top_values)].copy()\n",
    "\n",
    "    if not filtered_df.empty:\n",
    "        crosstab = pd.crosstab(filtered_df['country'], filtered_df['success'])\n",
    "        if crosstab.shape[0] > 1 and crosstab.shape[1] > 1:\n",
    "            chi2, p, dof, expected = stats.chi2_contingency(crosstab)\n",
    "            display(crosstab)\n",
    "            display(pd.DataFrame(expected, index=crosstab.index, columns=crosstab.columns))\n",
    "            print(f\"Chi-squared: {chi2:.4f}, p-value: {p:.4f}, dof: {dof}\")\n",
    "\n",
    "            n = crosstab.sum().sum()\n",
    "            min_dim = min(crosstab.shape) - 1\n",
    "            cramers_v = np.sqrt(chi2 / (n * min_dim)) if min_dim > 0 else float('nan')\n",
    "            print(f\"Cramer's V: {cramers_v:.4f}\")\n",
    "\n",
    "            low_expected = (expected < 5).sum()\n",
    "            total_cells = expected.size\n",
    "            if low_expected > 0:\n",
    "                print(f\"Warning: {low_expected} out of {total_cells} cells have expected count < 5.\")\n",
    "        else:\n",
    "            print(\"Insufficient dimensions for Chi-squared test.\")\n",
    "    else:\n",
    "        print(\"Filtered data is empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3bd403",
   "metadata": {},
   "source": [
    "## Summary and Interpretation Guidance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Alpha level used: {alpha}\")\n",
    "print(\"Refer to earlier cells for detailed test outputs, p-values, and effect sizes.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}